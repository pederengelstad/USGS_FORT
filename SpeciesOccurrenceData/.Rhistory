cl<-makeCluster(no_cores, methods = F)
stopCluster(cl)
#parallel option
dir.create(file.path(out$input$output.dir, "ProbTiff"))
out$input$output.dir
#Updates
#1.0.1    Added methods=F to make cluster to boost CPU load times
ApplyModel = "E:/Users/engelstad/USGS/data/ravennagrass/model_output/CovariateCorrelationOutputMDS_KDE_initial.csv"
ScriptPath<-'C:/Users/pederengelstad/.vistrails/userpackages/sahm_2_1_1/pySAHM/Resources/R_Modules'
# source(file.path(ScriptPath,"LoadRequiredCode.r"))
ScriptPath.Local <- ScriptPath
load("E:/Users/engelstad/USGS/data/ravennagrass/model_output/modelWorkspace", envir = environment())
library(parallel, quietly=T)
library(rgdal, quietly=T)
library(raster, quietly=T)
if(ApplyModel != F){
csv = read.csv(ApplyModel, header = T, stringsAsFactors = F)
out$dat$input$ParcTemplate = csv[2,1]
csv = csv[2, 4:length(csv)]
out$dat$tif.ind = csv
out$input$output.dir = file.path(dirname(ApplyModel))
out$dat$bname = file.path(dirname(ApplyModel), out$input$script.name)
}
cellfromrow
#pre-defined variables
out$input$make.binary.tif = FALSE
out$input$make.p.tif = TRUE
out$input$make.bin.tif = FALSE
out$input$MESS = FALSE
out$input$ResidMaps = FALSE
Model = out$input$script.name
make.p.tif = TRUE
make.bin.tif = FALSE
make.binary.tif = FALSE
residSmooth=NULL
#proc.tiff variables
model = out$mods$final.mod
vnames = names(out$dat$ma$train$dat)[-1]
tif.dir = out$dat$tif.dir$dname
filenames = out$dat$tif.ind
factor.levels = out$dat$factor.levels
thresh = out$mods$auc.output$thresh
make.p.tif = make.p.tif
outfile.p = paste(out$dat$bname, "_prob_map.tif", sep = "")
outfile.bin = paste(out$dat$bname, "_bin_map.tif", sep = "")
tsize = 50.0
NAval = -3000
fnames = out$dat$tif.names
Model = out$input$script.name
# deconstruct proc.tiff
if(is.null(factor.levels)) factor.levels <- NA
MESS = MOD = out$input$MESS
if(is.null(thresh)) thresh <- 0.5
nvars <- length(vnames)
vnames.final.mod <- out$mods$vnames
nvars.final <- length(vnames.final.mod)
names(filenames) <- sub("_categorical", "", names(filenames))
fullnames <- as.character(filenames[match(vnames, names(filenames))])
goodfiles <- file.access(fullnames) == 0
if(!all(goodfiles)) stop(paste("ERROR: the following image files are missing:", paste(fullnames[!goodfiles], collapse=", ")))
if(nvars.final < 1) MESS = FALSE
if(nvars.final == 1) MOD = FALSE
gi <- GDALinfo(fullnames[1])
dims <- as.vector(gi)[1:2]
ps <- as.vector(gi)[6:7]
ll <- as.vector(gi)[4:5]
pref <- attr(gi,"projection")
RasterInfo = raster(fullnames[2])
RasterInfo@file@datanotation <- "FLT4S"
NAval <- -3.399999999999999961272e+38
if(!is.na(match("AREA_OR_POINT=Point", attr(gi, "mdata")))){
xx <- RasterInfo  #this shifts by a half pixel
nrow(xx) <- nrow(xx) - 1
ncol(xx) <- ncol(xx) - 1
rs <- res(xx)
xmin(RasterInfo) <- xmin(RasterInfo) - 0.5 * rs[1]
xmax(RasterInfo) <- xmax(RasterInfo) - 0.5 * rs[1]
ymin(RasterInfo) <- ymin(RasterInfo) + 0.5 * rs[2]
ymax(RasterInfo) <- ymax(RasterInfo) + 0.5 * rs[2]
}
MB.per.row <- dims[2] * nvars * 32/8/1000/1024
if(MESS) MB.per.row <- MB.per.row * 8 #use more blocks for mess
nrows <- min(round(tsize/MB.per.row),dims[1])
bs <- c(nrows,dims[2])
chunksize <- bs[1] * bs[2]
tr <- blockSize(RasterInfo,chunksize=chunksize)
FactorInd <- which(!is.na(match(vnames,names(factor.levels))), arr.ind = TRUE)
if((nvars-length(FactorInd)) == 0) MESS <- MOD <- FALSE
if(tr$n<10 | getRversion()<2.14) multCore <- FALSE
tile.start <- seq(from = 1, to = tr$n, by = ceiling(tr$n/(detectCores()-1)))
outfile.p = file.path(out$input$output.dir, "ProbTiff", "_prob_map.tif")
varlist = c('tr','dims','MESS','MOD','nvars','fullnames','nvars.final','vnames','NAval'
,'factor.levels','model','Model','pred.fct','make.binary.tif','make.p.tif','RasterInfo'
,'outfile.p','outfile.bin','thresh','vnames.final.mod', 'make.bin.tif','ScriptPath.Local'
,'residSmooth')
source("C:/Users/pederengelstad/.vistrails/userpackages/sahm_2_1_1/pySAHM/Resources/R_Modules/Experimental/parRaster_probonly.r"
, local = F)
#parallel option
dir.create(file.path(out$input$output.dir, "ProbTiff"))
no_cores = detectCores()-1
cl<-makeCluster(no_cores, methods = F)
clusterExport(cl=cl, varlist = varlist, envir = environment())
clusterCall(cl = cl,fun =  function() { source(file.path(ScriptPath.Local,"CalcMESS.r"), local = F) })
clusterCall(cl = cl,fun =  function() { source(file.path(ScriptPath.Local,"pred.fct.r"), local = F) })
clusterEvalQ(cl = cl, expr = library(raster))
clusterEvalQ(cl = cl, expr = library(foreign))
clusterEvalQ(cl = cl, expr = library(gbm))
parLapply(cl,X = tile.start, fun=parRaster
, dims = dims
, factor.levels = factor.levels
, fullnames = fullnames
, maDir = out$input$ma.name
, make.p.tif = make.p.tif
, MESS = MESS
, MOD = MOD
, model = model
, Model = Model
, NAval = NAval
, nToDo = ceiling(tr$n/(detectCores()-1))
, nvars.final = nvars.final
, outfile.bin = outfile.bin
, outfile.p = outfile.p
, pred.fct = pred.fct
, RasterInfo = RasterInfo
# , residSmooth = residSmooth
, thresh = thresh
, tr = tr
, train.dat = out$dat$ma$train$dat
, vnames.final.mod = vnames.final.mod
, vnames = vnames
, template = out$dat$input$ParcTemplate
)
stopCluster(cl)
#Updates
#1.0.1    Added methods=F to make cluster to boost CPU load times
ApplyModel = "E:/Users/engelstad/USGS/data/ravennagrass/model_output/CovariateCorrelationOutputMDS_KDE_initial.csv"
ScriptPath<-'C:/Users/pederengelstad/.vistrails/userpackages/sahm_2_1_1/pySAHM/Resources/R_Modules'
# source(file.path(ScriptPath,"LoadRequiredCode.r"))
ScriptPath.Local <- ScriptPath
load("E:/Users/engelstad/USGS/data/ravennagrass/model_output/modelWorkspace", envir = environment())
library(parallel, quietly=T)
library(rgdal, quietly=T)
library(raster, quietly=T)
if(ApplyModel != F){
csv = read.csv(ApplyModel, header = T, stringsAsFactors = F)
out$dat$input$ParcTemplate = csv[2,1]
csv = csv[2, 4:length(csv)]
out$dat$tif.ind = csv
out$input$output.dir = file.path(dirname(ApplyModel))
out$dat$bname = file.path(dirname(ApplyModel), out$input$script.name)
}
cellfromrow
#pre-defined variables
out$input$make.binary.tif = FALSE
out$input$make.p.tif = TRUE
out$input$make.bin.tif = FALSE
out$input$MESS = FALSE
out$input$ResidMaps = FALSE
Model = out$input$script.name
make.p.tif = TRUE
make.bin.tif = FALSE
make.binary.tif = FALSE
residSmooth=NULL
#proc.tiff variables
model = out$mods$final.mod
vnames = names(out$dat$ma$train$dat)[-1]
tif.dir = out$dat$tif.dir$dname
filenames = out$dat$tif.ind
factor.levels = out$dat$factor.levels
thresh = out$mods$auc.output$thresh
make.p.tif = make.p.tif
outfile.p = paste(out$dat$bname, "_prob_map.tif", sep = "")
outfile.bin = paste(out$dat$bname, "_bin_map.tif", sep = "")
tsize = 50.0
NAval = -3000
fnames = out$dat$tif.names
Model = out$input$script.name
# deconstruct proc.tiff
if(is.null(factor.levels)) factor.levels <- NA
MESS = MOD = out$input$MESS
if(is.null(thresh)) thresh <- 0.5
nvars <- length(vnames)
vnames.final.mod <- out$mods$vnames
nvars.final <- length(vnames.final.mod)
names(filenames) <- sub("_categorical", "", names(filenames))
fullnames <- as.character(filenames[match(vnames, names(filenames))])
goodfiles <- file.access(fullnames) == 0
if(!all(goodfiles)) stop(paste("ERROR: the following image files are missing:", paste(fullnames[!goodfiles], collapse=", ")))
if(nvars.final < 1) MESS = FALSE
if(nvars.final == 1) MOD = FALSE
gi <- GDALinfo(fullnames[1])
dims <- as.vector(gi)[1:2]
ps <- as.vector(gi)[6:7]
ll <- as.vector(gi)[4:5]
pref <- attr(gi,"projection")
RasterInfo = raster(fullnames[2])
RasterInfo@file@datanotation <- "FLT4S"
NAval <- -3.399999999999999961272e+38
if(!is.na(match("AREA_OR_POINT=Point", attr(gi, "mdata")))){
xx <- RasterInfo  #this shifts by a half pixel
nrow(xx) <- nrow(xx) - 1
ncol(xx) <- ncol(xx) - 1
rs <- res(xx)
xmin(RasterInfo) <- xmin(RasterInfo) - 0.5 * rs[1]
xmax(RasterInfo) <- xmax(RasterInfo) - 0.5 * rs[1]
ymin(RasterInfo) <- ymin(RasterInfo) + 0.5 * rs[2]
ymax(RasterInfo) <- ymax(RasterInfo) + 0.5 * rs[2]
}
MB.per.row <- dims[2] * nvars * 32/8/1000/1024
if(MESS) MB.per.row <- MB.per.row * 8 #use more blocks for mess
nrows <- min(round(tsize/MB.per.row),dims[1])
bs <- c(nrows,dims[2])
chunksize <- bs[1] * bs[2]
tr <- blockSize(RasterInfo,chunksize=chunksize)
FactorInd <- which(!is.na(match(vnames,names(factor.levels))), arr.ind = TRUE)
if((nvars-length(FactorInd)) == 0) MESS <- MOD <- FALSE
if(tr$n<10 | getRversion()<2.14) multCore <- FALSE
tile.start <- seq(from = 1, to = tr$n, by = ceiling(tr$n/(detectCores()-1)))
outfile.p = file.path(out$input$output.dir, "ProbTiff", "_prob_map.tif")
varlist = c('tr','dims','MESS','MOD','nvars','fullnames','nvars.final','vnames','NAval'
,'factor.levels','model','Model','pred.fct','make.binary.tif','make.p.tif','RasterInfo'
,'outfile.p','outfile.bin','thresh','vnames.final.mod', 'make.bin.tif','ScriptPath.Local'
,'residSmooth')
source("C:/Users/pederengelstad/.vistrails/userpackages/sahm_2_1_1/pySAHM/Resources/R_Modules/Experimental/parRaster_probonly.r"
, local = F)
#parallel option
dir.create(file.path(out$input$output.dir, "ProbTiff"))
no_cores = detectCores()-1
cl<-makeCluster(no_cores, methods = F)
clusterExport(cl=cl, varlist = varlist, envir = environment())
clusterCall(cl = cl,fun =  function() { source(file.path(ScriptPath.Local,"CalcMESS.r"), local = F) })
clusterCall(cl = cl,fun =  function() { source(file.path(ScriptPath.Local,"pred.fct.r"), local = F) })
clusterEvalQ(cl = cl, expr = library(raster))
clusterEvalQ(cl = cl, expr = library(foreign))
clusterEvalQ(cl = cl, expr = library(gbm))
parLapply(cl,X = tile.start, fun=parRaster
, dims = dims
, factor.levels = factor.levels
, fullnames = fullnames
, maDir = out$input$ma.name
, make.p.tif = make.p.tif
, MESS = MESS
, MOD = MOD
, model = model
, Model = Model
, NAval = NAval
, nToDo = ceiling(tr$n/(detectCores()-1))
, nvars.final = nvars.final
, outfile.bin = outfile.bin
, outfile.p = outfile.p
, pred.fct = pred.fct
, RasterInfo = RasterInfo
# , residSmooth = residSmooth
, thresh = thresh
, tr = tr
, train.dat = out$dat$ma$train$dat
, vnames.final.mod = vnames.final.mod
, vnames = vnames
, template = out$dat$input$ParcTemplate
)
stopCluster(cl)
#Updates
#1.0.1    Added methods=F to make cluster to boost CPU load times
ApplyModel = "E:/Users/engelstad/USGS/data/ravennagrass/model_output/CovariateCorrelationOutputMDS_KDE_initial.csv"
ScriptPath<-'C:/Users/pederengelstad/.vistrails/userpackages/sahm_2_1_1/pySAHM/Resources/R_Modules'
# source(file.path(ScriptPath,"LoadRequiredCode.r"))
ScriptPath.Local <- ScriptPath
load("E:/Users/engelstad/USGS/data/ravennagrass/model_output/modelWorkspace", envir = environment())
library(parallel, quietly=T)
library(rgdal, quietly=T)
library(raster, quietly=T)
if(ApplyModel != F){
csv = read.csv(ApplyModel, header = T, stringsAsFactors = F)
out$dat$input$ParcTemplate = csv[2,1]
csv = csv[2, 4:length(csv)]
out$dat$tif.ind = csv
out$input$output.dir = file.path(dirname(ApplyModel))
out$dat$bname = file.path(dirname(ApplyModel), out$input$script.name)
}
cellfromrow
#pre-defined variables
out$input$make.binary.tif = FALSE
out$input$make.p.tif = TRUE
out$input$make.bin.tif = FALSE
out$input$MESS = FALSE
out$input$ResidMaps = FALSE
Model = out$input$script.name
make.p.tif = TRUE
make.bin.tif = FALSE
make.binary.tif = FALSE
residSmooth=NULL
#proc.tiff variables
model = out$mods$final.mod
vnames = names(out$dat$ma$train$dat)[-1]
tif.dir = out$dat$tif.dir$dname
filenames = out$dat$tif.ind
factor.levels = out$dat$factor.levels
thresh = out$mods$auc.output$thresh
make.p.tif = make.p.tif
outfile.p = paste(out$dat$bname, "_prob_map.tif", sep = "")
outfile.bin = paste(out$dat$bname, "_bin_map.tif", sep = "")
tsize = 50.0
NAval = -3000
fnames = out$dat$tif.names
Model = out$input$script.name
# deconstruct proc.tiff
if(is.null(factor.levels)) factor.levels <- NA
MESS = MOD = out$input$MESS
if(is.null(thresh)) thresh <- 0.5
nvars <- length(vnames)
vnames.final.mod <- out$mods$vnames
nvars.final <- length(vnames.final.mod)
names(filenames) <- sub("_categorical", "", names(filenames))
fullnames <- as.character(filenames[match(vnames, names(filenames))])
goodfiles <- file.access(fullnames) == 0
if(!all(goodfiles)) stop(paste("ERROR: the following image files are missing:", paste(fullnames[!goodfiles], collapse=", ")))
if(nvars.final < 1) MESS = FALSE
if(nvars.final == 1) MOD = FALSE
gi <- GDALinfo(fullnames[1])
dims <- as.vector(gi)[1:2]
ps <- as.vector(gi)[6:7]
ll <- as.vector(gi)[4:5]
pref <- attr(gi,"projection")
RasterInfo = raster(fullnames[2])
RasterInfo@file@datanotation <- "FLT4S"
NAval <- -3.399999999999999961272e+38
if(!is.na(match("AREA_OR_POINT=Point", attr(gi, "mdata")))){
xx <- RasterInfo  #this shifts by a half pixel
nrow(xx) <- nrow(xx) - 1
ncol(xx) <- ncol(xx) - 1
rs <- res(xx)
xmin(RasterInfo) <- xmin(RasterInfo) - 0.5 * rs[1]
xmax(RasterInfo) <- xmax(RasterInfo) - 0.5 * rs[1]
ymin(RasterInfo) <- ymin(RasterInfo) + 0.5 * rs[2]
ymax(RasterInfo) <- ymax(RasterInfo) + 0.5 * rs[2]
}
MB.per.row <- dims[2] * nvars * 32/8/1000/1024
if(MESS) MB.per.row <- MB.per.row * 8 #use more blocks for mess
nrows <- min(round(tsize/MB.per.row),dims[1])
bs <- c(nrows,dims[2])
chunksize <- bs[1] * bs[2]
tr <- blockSize(RasterInfo,chunksize=chunksize)
FactorInd <- which(!is.na(match(vnames,names(factor.levels))), arr.ind = TRUE)
if((nvars-length(FactorInd)) == 0) MESS <- MOD <- FALSE
if(tr$n<10 | getRversion()<2.14) multCore <- FALSE
tile.start <- seq(from = 1, to = tr$n, by = ceiling(tr$n/(detectCores()-1)))
outfile.p = file.path(out$input$output.dir, "ProbTiff", "_prob_map.tif")
varlist = c('tr','dims','MESS','MOD','nvars','fullnames','nvars.final','vnames','NAval'
,'factor.levels','model','Model','pred.fct','make.binary.tif','make.p.tif','RasterInfo'
,'outfile.p','outfile.bin','thresh','vnames.final.mod', 'make.bin.tif','ScriptPath.Local'
,'residSmooth')
source("C:/Users/pederengelstad/.vistrails/userpackages/sahm_2_1_1/pySAHM/Resources/R_Modules/Experimental/parRaster_probonly.r"
, local = F)
#parallel option
dir.create(file.path(out$input$output.dir, "ProbTiff"))
no_cores = detectCores()-1
cl<-makeCluster(no_cores, methods = F)
clusterExport(cl=cl, varlist = varlist, envir = environment())
clusterCall(cl = cl,fun =  function() { source(file.path(ScriptPath.Local,"CalcMESS.r"), local = F) })
clusterCall(cl = cl,fun =  function() { source(file.path(ScriptPath.Local,"pred.fct.r"), local = F) })
clusterEvalQ(cl = cl, expr = library(raster))
clusterEvalQ(cl = cl, expr = library(foreign))
clusterEvalQ(cl = cl, expr = library(gbm))
parLapply(cl,X = tile.start, fun=parRaster
, dims = dims
, factor.levels = factor.levels
, fullnames = fullnames
, maDir = out$input$ma.name
, make.p.tif = make.p.tif
, MESS = MESS
, MOD = MOD
, model = model
, Model = Model
, NAval = NAval
, nToDo = ceiling(tr$n/(detectCores()-1))
, nvars.final = nvars.final
, outfile.bin = outfile.bin
, outfile.p = outfile.p
, pred.fct = pred.fct
, RasterInfo = RasterInfo
# , residSmooth = residSmooth
, thresh = thresh
, tr = tr
, train.dat = out$dat$ma$train$dat
, vnames.final.mod = vnames.final.mod
, vnames = vnames
, template = out$dat$input$ParcTemplate
)
stopCluster(cl)
ens.mask.out="E:/Users/engelstad/USGS/data/fountaingrass/lk_mead/lkmead_clip.tif"
output = "E:/Users/engelstad/USGS/data/scratch/lkmead_color.tif"
color.config = "E:/Users/engelstad/USGS/data/colorconfig.txt"
gdalUtils::gdaldem(mode = "color-relief"
,input_dem = ens.mask.out
,output = output
, alpha = T, co = c("COMPRESS=LZW", "TILED=YES") ,color_text_file = color.config)
install.packages("SSDM")
library(SSDM)
SSDM::gui()
install.packages("shinyFiles")
install.packages("shinyFiles")
devtools::install_github("sylvainschmitt/SSDM")
library(SSDM)
gui()
list.of.packages <- c("devtools","gsheet","jsonlite","rgdal","rgeos","ritis","scrubr",'spocc',"stringr","taxize","tidyverse")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
################################
list.of.packages <- c("devtools","gsheet","jsonlite","rgdal","rgeos","ritis","scrubr",'spocc',"stringr","taxize","tidyverse")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
setwd('E:/Users/engelstad/GitHub/USGS_FORT/SpeciesOccurrenceData/')
setwd('E:/Users/engelstad/GitHub/USGS_FORT/SpeciesOccurrenceData/')
# !!! if you don't already have the latest version of spocc and/or taxize from github, uncomment the line below and run !!!
# remotes::install_github("ropensci/spocc")
# remotes::install_github("ropensci/taxize")
getwd()
setwd('E:/Users/engelstad/GitHub/USGS_FORT/SpeciesOccurrenceData/')
setwd('E:/Users/engelstad/GitHub/USGS_FORT/SpeciesOccurrenceData/')
################################################################################
#2. Check for synonyms from ITIS and develop a finalized species list
library(tidyverse, verbose = F)
################################################################################
#2. Check for synonyms from ITIS and develop a finalized species list
library(tidyverse, verbose = F, quietly = T, warn.conflicts = F)
source('E:/Users/engelstad/GitHub/USGS_FORT/SpeciesOccurrenceData/SpeciesProcessing.R')
setwd('E:/Users/engelstad/GitHub/USGS_FORT_2/SpeciesOccurrenceData/')
################################################################################
#2. Check for synonyms from ITIS and develop a finalized species list
library(tidyverse, verbose = F, quietly = T, warn.conflicts = F)
source('./SpeciesProcessing.R')
# sp_list = suppressWarnings(readLines(''))
sp_list = c('Sequoia sempervirens')
species_processing(sort(sp_list),USDA = T)
source('./SpeciesProcessing.R')
# sp_list = suppressWarnings(readLines(''))
sp_list = c('Sequoia sempervirens')
species_processing(sort(sp_list),USDA = T)
sp_df
species_search_list
spocc_rec = spocc::occ(query = species_search_list, has_coords = FALSE)
spocc_rec$gbif$data
spocc_rec$bison$data
spocc_rec$inat$data
spocc_rec$ecoengine$data
spocc_rec$idigbio$data
gbif_df = occ2df(spocc_rec$gbif)
gbif_df = spocc::occ2df(spocc_rec$gbif)
gbif_df
spocc_rec = spocc::occ(query = species_search_list, has_coords = FALSE, limit = 99999)
gbif_df = spocc::occ2df(spocc_rec$gbif)
gbif_df
spocc_rec$bison$data$Sequoia_sempervirens
occ(query = 'Sequoia sempervirens', from = "bison")
spocc::occ(query = 'Sequoia sempervirens', from = "bison")
species_search_list
spocc::occ(query = species_search_list, from = "bison")
spocc::occ(query = species_search_list, from = "bison", limit = 99999)
spocc_rec = spocc::occ(query = species_search_list,from = c('bison'), has_coords = FALSE, limit = 99999)
spocc_rec
species_search_list
spocc_rec
spocc_rec = spocc::occ(query = species_search_list,from = c('gbif','bison','ecoengine','ecoengine','idigbio'), has_coords = FALSE, limit = 99999)
spocc_rec
spocc_rec
gbif_df = spocc::occ2df(spocc_rec$gbif)
bison_df = spocc::occ2df(spocc_rec$bison)
spocc_rec$ecoengine
idigbio_df = spocc::occ2df(spocc_rec$idigbio)
idigbio_df
View(idigbio_df)
write.csv(gbif_df, "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/gbif_records.csv")
gbif_df = as.data.frame(spocc::occ2df(spocc_rec$gbif))
write.csv(gbif_df, "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/gbif_records.csv")
gbif_df
write.csv(x = gbif_df, file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/gbif_records.csv")
write.csv(x = gbif_df, file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/gbif_records.csv", sep = ",")
write.csv(x = gbif_df, file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/gbif_records.txt")
write.csv(x = as.data.frame(gbif_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/gbif_records.txt")
write.csv(x = as.data.frame(bison_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/bison_records.csv")
write.csv(x = as.data.frame(idigbio_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/idigbio_records.csv")
View(bison_df)
View(gbif_df)
View(idigbio_df)
View(idigbio_df)
names(gbif_df)
gbif_df[, order(names(gbif_df))]
gbif_df = gbif_df[, order(names(gbif_df))]
gbif_df
write.csv(x = as.data.frame(gbif_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/gbif_records.csv")
gbif_df = gbif_df %>%
select(-networkKeys)
write.csv(x = as.data.frame(gbif_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/gbif_records.csv")
write.csv(x = as.data.frame(gbif_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/gbif_records.csv")
bison_df = bison_df[, order(names(bison_df))]
write.csv(x = as.data.frame(bison_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/bison_records.csv")
idigbio_df = spocc::occ2df(spocc_rec$idigbio)
idigbio_df = idigbio_df[, order(names(idigbio_df))]
write.csv(x = as.data.frame(idigbio_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/idigbio_records.csv")
idigbio_df = idigbio_df %>%
select(-commonnames)
write.csv(x = as.data.frame(idigbio_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/idigbio_records.csv")
write.csv(x = as.data.frame(idigbio_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/idigbio_records.csv")
idigbio_df %>%
select(-(commonnames, flags, mediarecords, recordids))
idigbio_df %>%
select(-commonnames, -flags, -mediarecords, -recordids)
idigbio_df = spocc::occ2df(spocc_rec$idigbio)
idigbio_df = idigbio_df[, order(names(idigbio_df))]
idigbio_df = idigbio_df %>%
select(-commonnames, -flags, -mediarecords, -recordids)
write.csv(x = as.data.frame(idigbio_df), file = "E:/Users/engelstad/USGS/OccurrenceData/BW_CoastRedwood/idigbio_records.csv")
